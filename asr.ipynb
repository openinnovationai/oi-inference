{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81121296-ddbf-47a0-aef8-1adda6d9c8fe",
   "metadata": {},
   "source": [
    "### OICM Inference for models deployed with: OI SERVE / vLLM\n",
    "##### automatic-speech-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4e4c02-2e4a-4008-a889-93c5b79d1f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b727fc24-64e5-411e-83e9-2f9933bc9dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('OI_API_KEY') # Your valid api key\n",
    "deployment_id = os.getenv('OI_DEPLOYMENT_ID') # deployment id\n",
    "base_url = f\"https://inference.stg.openinnovation.ai/models/{deployment_id}/proxy/v1\" # change \"stg\" to your environment\n",
    "model_name = \"openai/whisper-large-v3\" # change it to your model name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5dc6a-7e43-4c14-acf5-d26ded6f1562",
   "metadata": {},
   "source": [
    "#### Using OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf395e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006441a5-1424-4725-a558-966a640e0732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file_path = \"./sample.wav\"  # Replace with your actual file path\n",
    "\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    files = {\n",
    "        \"file\": audio_file\n",
    "    }\n",
    "\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=model_name, \n",
    "        file=audio_file\n",
    "    )\n",
    "\n",
    "transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475f6e7-82f1-4f38-a67d-0b458674c032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
